{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yF9NYSxN67i0"
   },
   "source": [
    "# DSC Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JwaB8_je67i2"
   },
   "source": [
    "## <center>0. Project Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZWXYkpM67i3"
   },
   "source": [
    "### Steps\n",
    "1. Project definition\n",
    "2. Data preparation\n",
    "3. Model Building\n",
    "4. Model Validation\n",
    "5. Model Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LAEG6XzS67i4"
   },
   "source": [
    "## <center> 1. Libraries and Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2qKio0Av67i4"
   },
   "source": [
    "In this first step we defined the directory (with our data, IESEG library and programs) and the external libraries (that we used to run some pieces of code). A more detailed explanation on the usefulness of each library can be found in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUuIA1UG67i5"
   },
   "outputs": [],
   "source": [
    "path=\"C:/Users/bthomasemil/Documents/Predictive/Project\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8laqPpZ67i8",
    "outputId": "81a37d14-1178-4940-a47f-0fc7be76f233"
   },
   "outputs": [],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1575161699499,
     "user": {
      "displayName": "Carlos Montenegro",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtHikTCGDvfTJFbZW1tSjSJHHTiWjnkzwtaprc4uU=s64",
      "userId": "01067219476206912429"
     },
     "user_tz": -60
    },
    "id": "wi9J0waz67i_",
    "outputId": "77d26a6b-0fce-419c-86b4-2595ec6ed9d3"
   },
   "outputs": [],
   "source": [
    "#External Libraries specifically added for predictive analysis\n",
    "import sys\n",
    "sys.path.append(path)\n",
    "import numpy                as np\n",
    "import pandas               as pd\n",
    "import seaborn              as sns\n",
    "from pandas                 import DataFrame\n",
    "from pandas                 import read_csv\n",
    "from pandas                 import pivot_table\n",
    "from pandas                 import Series\n",
    "from pandas                 import get_dummies\n",
    "from numpy                  import random\n",
    "from numpy                  import where\n",
    "from numpy                  import nan\n",
    "from numpy                  import array\n",
    "from sklearn.ensemble       import RandomForestClassifier\n",
    "from sklearn.ensemble       import GradientBoostingClassifier\n",
    "from sklearn.metrics        import accuracy_score\n",
    "from sklearn.metrics        import roc_auc_score\n",
    "from sklearn.metrics        import auc\n",
    "from sklearn.metrics        import recall_score\n",
    "from sklearn.cluster        import KMeans\n",
    "from sklearn.tree           import DecisionTreeClassifier\n",
    "from sklearn.linear_model   import LogisticRegression \n",
    "from sklearn.svm            import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors      import KNeighborsClassifier\n",
    "from matplotlib             import pyplot\n",
    "from scipy.stats.mstats     import winsorize #we dont used it\n",
    "from scipy.stats            import pearsonr\n",
    "from matplotlib             import pyplot\n",
    "from ieseg                  import partition\n",
    "from ieseg                  import roc\n",
    "from ieseg                  import lift\n",
    "from ieseg                  import cumulativeResponse\n",
    "from ieseg                  import cumulativeGains\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "#External ibraries specifically added for segmentation analysis\n",
    "from sklearn.cluster        import AgglomerativeClustering\n",
    "from pandas                 import to_numeric\n",
    "from matplotlib             import pyplot\n",
    "from mpl_toolkits.mplot3d   import Axes3D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n95ITmf367jB"
   },
   "source": [
    "## <center> 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBKF-M5767jC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Paths\n",
    "directory = path\n",
    "inputData = directory + \"/Data\"\n",
    "sandbox   = directory + \"/Sandbox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGHAWQM367jE"
   },
   "outputs": [],
   "source": [
    "# - DATA PREP - #\n",
    "# Functions used in this notebook\n",
    "\n",
    "# Data Inspection Tools\n",
    "def explore(data):\n",
    "    print(data.head())\n",
    "    print(data.tail())\n",
    "    print(data.info())\n",
    "    print(data.columns)\n",
    "    print(data.dtypes)\n",
    "    print(data.shape)\n",
    "    print(data.describe())\n",
    "\n",
    "# Function to change zipcode to province \n",
    "def province(zipCode):\n",
    "    if((zipCode >= 1000) & (zipCode < 1300)):\n",
    "        return(\"Brussels\")\n",
    "    elif(zipCode < 1500):\n",
    "        return(\"Walloon Brabant\")\n",
    "    elif(zipCode < 2000):\n",
    "        return(\"Flemish Brabant\")\n",
    "    elif(zipCode < 3000):\n",
    "        return(\"Antwerp\")\n",
    "    elif(zipCode < 3500):\n",
    "        return(\"Flemish Brabant\")\n",
    "    elif(zipCode < 4000):\n",
    "        return(\"Limburg\")\n",
    "    elif(zipCode < 5000):\n",
    "        return(\"Liege\")\n",
    "    elif(zipCode < 6000):\n",
    "        return(\"Namur\")\n",
    "    elif(zipCode < 6600):\n",
    "        return(\"Hainaut\")\n",
    "    elif(zipCode < 7000):\n",
    "        return(\"Luxembourg\")\n",
    "    elif(zipCode < 8000):\n",
    "        return(\"Hainaut\")\n",
    "    elif(zipCode < 9000):\n",
    "        return(\"West Flanders\")\n",
    "    elif(zipCode < 10000):\n",
    "        return(\"East Flanders\")\n",
    "    else:\n",
    "        return(\"Missing\")\n",
    "\n",
    "# Function to change zipcode to  region  \n",
    "def region(zipCode):\n",
    "    if((zipCode >= 1000) & (zipCode < 1300)):\n",
    "          return(\"Brussels\")\n",
    "    elif(zipCode < 1500):\n",
    "          return(\"Wallonia\")\n",
    "    elif(zipCode < 2000):\n",
    "          return(\"Flanders\")\n",
    "    elif(zipCode < 3000):\n",
    "          return(\"Flanders\")\n",
    "    elif(zipCode < 3500):\n",
    "          return(\"Flanders\")\n",
    "    elif(zipCode < 4000):\n",
    "          return(\"Flanders\")\n",
    "    elif(zipCode < 5000):\n",
    "          return(\"Wallonia\")\n",
    "    elif(zipCode < 6000):\n",
    "          return(\"Wallonia\")\n",
    "    elif(zipCode < 6600):\n",
    "          return(\"Wallonia\")\n",
    "    elif(zipCode < 7000):\n",
    "          return(\"Wallonia\")\n",
    "    elif(zipCode < 8000):\n",
    "          return(\"Wallonia\")\n",
    "    elif(zipCode < 9000):\n",
    "          return(\"Flanders\")\n",
    "    elif(zipCode < 10000):\n",
    "          return(\"Flanders\")\n",
    "    else:\n",
    "          return(\"Missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4-qGPSN67jH"
   },
   "source": [
    "#### 2.2 Donor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGch9UMi67jJ",
    "outputId": "dbc64be2-4e4b-4622-efe6-796411840b2f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reading the data and saving it as a dataframe called donor\n",
    "donor = read_csv(inputData + \"/donors.csv\", sep = ';')\n",
    "\n",
    "#Call function to inspect the donor data\n",
    "explore(donor)\n",
    "    \n",
    "#Analyse Gender Column\n",
    "donor['gender'].unique()\n",
    "\n",
    "#Replace C S U with NA\n",
    "donor[donor.gender.isin(['U'])]=donor[donor.gender.isin(['U'])].replace(['U'], 'NA')\n",
    "\n",
    "#Check if it works\n",
    "(donor.gender == 'NA').sum()\n",
    "donor.tail()\n",
    "\n",
    "#Inspect observation for the language variable\n",
    "donor['language'].unique()\n",
    "\n",
    "#Integer coding for the language variable\n",
    "dictionary = {'N': 0, 'F': 1}\n",
    "donor = donor.replace({'language': dictionary})\n",
    "\n",
    "#Change the column name to make it more interpretable\n",
    "donor.rename(columns = {'language' : 'is_french'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oActQS_h67jL"
   },
   "source": [
    "#### 2.3 Gift Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2ff4kCa67jM",
    "outputId": "63f7164e-cddd-4651-83ee-8205d783fc8f"
   },
   "outputs": [],
   "source": [
    "#Reading the data and saving it as a dataframe called gifts\n",
    "gifts = read_csv(inputData + \"/gifts.csv\", sep = ';')\n",
    "\n",
    "#Inspect the data\n",
    "explore(gifts)\n",
    "\n",
    "#Analyse the column camp id\n",
    "gifts['campID'] = gifts['campID'].apply(str)\n",
    "\n",
    "#Replace 0 in camp ID to NA\n",
    "gifts['campID'] = gifts['campID'].replace('0', 'NA')\n",
    "\n",
    "#Check the replacement of NAs\n",
    "(gifts.campID == 'NA').sum()\n",
    "\n",
    "#Extracting Year and Month from the Date column\n",
    "gifts['date'] = pd.to_datetime(gifts['date'])\n",
    "gifts['year'] = gifts['date'].dt.year\n",
    "gifts['months'] = gifts['date'].dt.month\n",
    "gifts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qJaQASM67jO",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# - DATA PREP - #\n",
    "\n",
    "#Extracting the most recent date before 2013 (assuming campaign starts on 2013-01-01)\n",
    "gifts_before_2013 = gifts[(gifts.date < '2012-12-17')]\n",
    "gifts_date = gifts_before_2013.groupby('donorID')['date'].max()\n",
    "\n",
    "# SLice for 1 year\n",
    "# Extracting observations in which donations have been made 1 year prior to the campaign\n",
    "gifts_new_1y = gifts[(gifts.date < '2012-12-17') & (gifts.date > '2011-12-17')] \n",
    "\n",
    "#Grouping by Donor ofr 1 year \n",
    "gifts_1_year = gifts_new_1y.groupby('donorID')['amount'].sum()\n",
    "\n",
    "#Slice for 3 years \n",
    "# Extracting observations in which donations have been made 3 year prior to the campaign\n",
    "gifts_new_3y = gifts[(gifts.date < '2012-12-17') & (gifts.date > '2009-12-17')]\n",
    "gifts_3_year = gifts_new_3y.groupby('donorID')['amount'].sum()\n",
    "\n",
    "#Slice for 5 years \n",
    "# Extracting observations in which donations have been made 5 year prior to the campaign\n",
    "gifts_new_5y = gifts[(gifts.date < '2012-12-17') & (gifts.date > '2007-12-17')]\n",
    "gifts_5_year = gifts_new_5y.groupby('donorID')['amount'].sum()\n",
    "\n",
    "#Slice for 10 years \n",
    "# Extracting observations in which donations have been made 10 year prior to the campaign\n",
    "gifts_new_10y = gifts[(gifts.date < '2012-12-17') & (gifts.date > '2002-12-17')]\n",
    "gifts_10_year = gifts_new_10y.groupby('donorID')['amount'].sum()\n",
    "\n",
    "#Slice for 18 years \n",
    "# Extracting observations in which donations have been made 18 year prior to the campaign\n",
    "gifts_new_18y = gifts[(gifts.date < '2012-12-17') & (gifts.date > '1995-1-17')]\n",
    "gifts_18_year = gifts_new_18y.groupby('donorID')['amount'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZys81DH67jQ"
   },
   "outputs": [],
   "source": [
    "# - DATA PREP - #\n",
    "\n",
    "# Create table for with total amount donated by donor in specific time period \n",
    "\n",
    "#Join data of 18y with 14y\n",
    "left_table = gifts_18_year\n",
    "right_table = gifts_10_year\n",
    "join_18_10 = pd.merge(left_table,\n",
    "        right_table,\n",
    "        how='left',\n",
    "        left_on='donorID',\n",
    "        right_on='donorID'\n",
    "        )\n",
    "#Join previous with 5y\n",
    "left_table = join_18_10\n",
    "right_table = gifts_5_year\n",
    "join_18_10_5 = pd.merge(left_table,\n",
    "        right_table,\n",
    "        how='left',\n",
    "        left_on='donorID',\n",
    "        right_on='donorID'\n",
    "        )\n",
    "#Join previous with 3y\n",
    "left_table = join_18_10_5\n",
    "right_table = gifts_3_year\n",
    "join_18_10_5_3 = pd.merge(left_table,\n",
    "        right_table,\n",
    "        how='left',\n",
    "        left_on='donorID',\n",
    "        right_on='donorID'\n",
    "        )\n",
    "#Join previous with 1y\n",
    "left_table = join_18_10_5_3\n",
    "right_table = gifts_1_year\n",
    "join_18_10_5_3_1 = pd.merge(left_table,\n",
    "        right_table,\n",
    "        how='left',\n",
    "        left_on='donorID',\n",
    "        right_on='donorID'\n",
    "        )\n",
    "\n",
    "#Changing names of columns\n",
    "join_18_10_5_3_1.columns = ['18y', '10y','5y', '3y', '1y']\n",
    "\n",
    "# Checking final result\n",
    "final_merge_gifts = join_18_10_5_3_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gVhYrAKG67jS",
    "outputId": "d887d1d2-cf3a-47b9-a112-d7caf2d83959"
   },
   "outputs": [],
   "source": [
    "# - DATA PREP - #\n",
    "\n",
    "\n",
    "#Transform the dataset for better interpretation\n",
    "\n",
    "#Create pivot with every year\n",
    "gifts_1 = gifts.pivot_table(index = 'donorID', columns = ['year'], values = 'amount', aggfunc = 'sum')\n",
    "#Create pivot with every month\n",
    "gifts_2 = gifts.pivot_table(index = 'donorID', columns = ['months'], values = 'amount', aggfunc = 'sum')\n",
    "# merge the two pivots in one table\n",
    "gifts_final = pd.merge(gifts_1, gifts_2, 'left', on= \"donorID\")\n",
    "#Fill NA with 0\n",
    "gifts_final = gifts_final.iloc[:, 0:].fillna(0)\n",
    "#Create Column 'frequency_gifts'\n",
    "gifts_final[\"frequency_gifts\"] = ((gifts_final.iloc[:, 0:20]) > 0.0).sum(axis = 1)\n",
    "#Create quarters\n",
    "gifts_final['Q1'] = gifts_final.iloc[:, -13:-10].sum(axis = 1)\n",
    "gifts_final['Q2'] = gifts_final.iloc[:, -10:-7].sum(axis = 1)\n",
    "gifts_final['Q3'] = gifts_final.iloc[:, 26:29].sum(axis = 1)\n",
    "gifts_final['Q4'] = gifts_final.iloc[:, 29:32].sum(axis = 1)\n",
    "#Drop months and yearss\n",
    "gifts_quarter = gifts_final.drop(gifts_final.iloc[:,0:20],axis=1)\n",
    "\n",
    "#Create table with quarters and gifts\n",
    "left_table = final_merge_gifts\n",
    "right_table = gifts_quarter\n",
    "gifts_final = pd.merge(left_table,\n",
    "                right_table,\n",
    "                how='left',\n",
    "                left_on='donorID',\n",
    "                right_on='donorID'\n",
    "                )\n",
    "\n",
    "#Most recent date added to the gifts data base\n",
    "left_table = gifts_final\n",
    "right_table = gifts_date\n",
    "gifts_final_2 = pd.merge(left_table,\n",
    "                right_table,\n",
    "                how='left',\n",
    "                left_on='donorID',\n",
    "                right_on='donorID'\n",
    "                )\n",
    "# create data frame with only this data\n",
    "date_1 = pd.to_datetime('2012-12-17')\n",
    "# add column 'recency_number' to new dataframe\n",
    "gifts_final_2['recency_number'] = date_1 - gifts_final_2['date'] \n",
    "# Covert to days instead of date\n",
    "gifts_final_2['recency_number'] = gifts_final_2['recency_number'] / np.timedelta64(1, 'D')\n",
    "#Check data\n",
    "gifts_final_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwycSdq267jV"
   },
   "source": [
    "#### 2.4 Campaign 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nu7rHv8167jV",
    "outputId": "42ca99f0-97f2-4d45-c1b3-d7fb61b545d1"
   },
   "outputs": [],
   "source": [
    "# - DATA PREP - #\n",
    "\n",
    "#Read the campaign 2013 table\n",
    "c_2013 = read_csv(inputData + \"/campaign20130411.csv\", sep = ';')\n",
    "explore(c_2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZyPiR06X67jY"
   },
   "source": [
    "#### 2.5 Data merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hS5rxTYk67jY"
   },
   "outputs": [],
   "source": [
    "# - DATA PREP - #\n",
    "\n",
    "#Merge the gifts_1 and c_2013 dataset\n",
    "left_1 = pd.merge(c_2013, gifts_final_2, \n",
    "         how = \"left\",\n",
    "        left_on = 'donorID', right_on = 'donorID')\n",
    "left_2 = pd.merge(left_1, donor, \n",
    "         how = \"left\",\n",
    "        left_on = 'donorID', right_on = 'donorID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbzNNuU167ja"
   },
   "source": [
    "#### 2.6 Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NPmSNRM67jb",
    "outputId": "a0630db0-ba3e-4929-ac63-e74e00f2c9b1"
   },
   "outputs": [],
   "source": [
    "# - DATA PREP - #\n",
    "\n",
    "#Create Dummies for gender, region and province\n",
    "final = pd.get_dummies(left_2, columns = ['gender'], drop_first=True)\n",
    "\n",
    "\n",
    "final['amount_missing'] = where(final['amount'].isnull(), 1, 0)\n",
    "\n",
    "# Appling condition for donations higher than 35 \n",
    "final['amount_missing'] = where(final['amount']>35, 1, 0)\n",
    "\n",
    "#Fix zipcode\n",
    "final['zipcode'] = final['zipcode'].str.replace(\"SW6 3PS\", '0')\n",
    "final['zipcode'] = final['zipcode'].str.replace(\" \", '0')\n",
    "final['zipcode'] = final['zipcode'].fillna(0)\n",
    "final['zipcode'] = final['zipcode'].astype(int)\n",
    "\n",
    "#Apply function to zipcode to add privince and regions names\n",
    "final[\"province\"] = final[\"zipcode\"].apply(lambda row:province(row))\n",
    "final[\"region\"] = final[\"zipcode\"].apply(lambda row:region(row))\n",
    "final.fillna(0)\n",
    "\n",
    "final = pd.get_dummies(final, columns = ['region','province'], drop_first=True)\n",
    "\n",
    "\n",
    "explore(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7Nj3tmX67jd",
    "outputId": "84f33a21-611b-42fb-91c6-b13f000f4d3c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# - DATA PREP - #\n",
    "\n",
    "# Drop useless columns\n",
    "final_model = final.drop(final[['donorID','amount','date','zipcode']], axis = 1)\n",
    "final_model.head()\n",
    "\n",
    "# Drop useless columns again\n",
    "table_model = final_model.drop(final_model.iloc[:, 5:17],axis = 1) \n",
    "table_model.tail()\n",
    "\n",
    "# Change NA for 0 \n",
    "for column in table_model.columns:\n",
    "    if column in [\"18y\",\"10y\",\"5y\",\"3y\",\"1y\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"Q1\",\"Q2\",\"Q3\",\"Q4\",\"recency_number\",'frequency_gifts']:\n",
    "        table_model[column][np.isnan(table_model[column])] = 0\n",
    "table_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdyaeD1v67jh",
    "outputId": "daded4e6-ee98-4293-e003-9fe616856fb8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# - DATA PREP - #\n",
    "\n",
    "#Standarization\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "table_model[['18y', '10y', '5y', '3y', '1y', 'frequency_gifts',\n",
    "             'Q1', 'Q2', 'Q3','Q4', 'recency_number']] = scaler.fit_transform(table_model[['18y', '10y', '5y', '3y', '1y', \n",
    "                                                                                           'frequency_gifts', 'Q1', 'Q2', 'Q3',\n",
    "                                                                                           'Q4', 'recency_number']])\n",
    "\n",
    "#print(norma_table_model.var()) \n",
    "table_model.head()\n",
    "\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCR0AUZ267jo",
    "outputId": "0e9942c6-e1e5-4275-c8e9-168f1a73876f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# - DATA PREP - #\n",
    "# Check if donations made are under represented \n",
    "import seaborn as sns\n",
    "sns.countplot(table_model[\"amount_missing\"], data = table_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= table_model \n",
    "split_strategy = [0.8,0.2]\n",
    "\n",
    "\n",
    "\n",
    "partitions = partition(dataFrame = data, splitStrategy = split_strategy)\n",
    "for (index,dataFrame) in enumerate(partitions):\n",
    "    print(f\"Partition {index} shape : {dataFrame.shape} ({len(dataFrame)/len(data)})\")\n",
    "\n",
    "trainingSet   = partitions[0]\n",
    "validationSet = partitions[1]\n",
    "\n",
    "\n",
    "\n",
    "#sm = SMOTE(random_state = 12, ratio = 1.0)\n",
    "#x_train, y_train = sm.fit_sample(trainingSet[features], trainingSet[target])\n",
    "#sns.countplot(y_train, data = trainingSet)\n",
    "#col=0\n",
    "#for feat in features:\n",
    "#    col+=1\n",
    "#     trainingSet[feat]=pd.DataFrame(data=x_train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['18y', '10y', '5y', '3y', '1y', 'frequency_gifts', 'Q1', 'Q2', 'Q3',\n",
    "       'Q4', 'recency_number', 'is_french', 'gender_F', 'gender_M',\n",
    "       'gender_NA', 'gender_S', 'region_Flanders',\n",
    "       'region_Wallonia', 'province_Brussels', 'province_East Flanders',\n",
    "       'province_Flemish Brabant', 'province_Hainaut', 'province_Liege',\n",
    "       'province_Limburg', 'province_Luxembourg', 'province_Namur',\n",
    "       'province_Walloon Brabant', 'province_West Flanders']\n",
    "target='amount_missing'\n",
    "\n",
    "# col=0\n",
    "# for feat in features:\n",
    "#     col+=1\n",
    "#     trainingSet[feat]=pd.DataFrame(data=X_train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainingSet.isnull().sum().sum())\n",
    "print(np.isnan(trainingSet).sum().sum())\n",
    "trainingSet.fillna(0)\n",
    "#Change the NA for 0 \n",
    "for column in trainingSet.columns:\n",
    "    trainingSet[column][np.isnan(trainingSet[column])] = 0\n",
    "trainingSet.head()\n",
    "print(trainingSet.isnull().sum().sum())\n",
    "print(np.isnan(trainingSet).sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TzMM8dsM67k3"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "## <center>3. Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rT2iZMfV67k7"
   },
   "source": [
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### 3.1 Segmentation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLdRlVyJ67k7"
   },
   "outputs": [],
   "source": [
    "for col in [\"10y\",\"5y\",\"3y\",\"1y\",\"Q1\",\"Q2\",\"Q3\",\"Q4\"]:\n",
    "    table_model[col] = winsorize(array(table_model[col]), limits=[0.00, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6WuA-um67k8"
   },
   "outputs": [],
   "source": [
    "data=table_model\n",
    "affi=\"manhattan\"\n",
    "link='single'\n",
    "thre=2\n",
    "clus=5\n",
    "\"\"\"\n",
    "\n",
    "This function returns the cluster of the segments.\n",
    "Input: Data, Affinity, Linkage, Distance\n",
    "Output: a table with the columns clusters!\"\n",
    "\n",
    "\"\"\"\n",
    "features=['Q3', 'frequency_gifts', '18y', 'province_Namur', 'province_Liege', 'province_Limburg', \n",
    "                    'gender_M', 'gender_NA', 'province_East Flanders', 'province_Brussels', 'province_Flemish Brabant',\n",
    "                    'province_Luxembourg', '3y', 'province_Walloon Brabant', 'province_West Flanders']\n",
    "#1st part\n",
    "kmeans = KMeans(n_clusters = clus)\n",
    "data[\"kmean cluster\"] = kmeans.fit_predict(data[features])\n",
    "\n",
    "# figure = pyplot.figure().gca(projection = \"3d\")\n",
    "# for cluster in range(5):\n",
    "#     figure.scatter(data[\"10y\"][data[\"kmean cluster\"] == cluster], \n",
    "#                    data[\"3y\"][data[\"kmean cluster\"] == cluster],\n",
    "#                    data[\"recency_number\"][data[\"kmean cluster\"] == cluster],\n",
    "#                    data[\"gender_NA\"][data[\"kmean cluster\"] == cluster],\n",
    "#                    data[\"5y\"][data[\"kmean cluster\"] == cluster],\n",
    "#                    data[\"is_french\"][data[\"kmean cluster\"] == cluster],\n",
    "#                    data[\"gender_S\"][data[\"kmean cluster\"] == cluster],\n",
    "#                    data[\"gender_C\"][data[\"kmean cluster\"] == cluster],\n",
    "#                    data[\"1y\"][data[\"kmean cluster\"] == cluster], \n",
    "#                    data[\"gender_F\"][data[\"kmean cluster\"] == cluster],\n",
    "#                    marker = 'o')\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEK55RcP67k9"
   },
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(data[['Q3', 'frequency_gifts', '18y', 'province_Namur', 'province_Liege', 'province_Limburg', \n",
    "                    'gender_M', 'gender_NA', 'province_East Flanders', 'province_Brussels', 'province_Flemish Brabant',\n",
    "                    'province_Luxembourg', '3y', 'province_Walloon Brabant', 'province_West Flanders']][data[\"kmean cluster\"]==i].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4063ynEz67jo"
   },
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "## <center>  4. Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPbGtae167jx"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### 4.1 Stepwise Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UI49QVW867j1"
   },
   "outputs": [],
   "source": [
    "tree         = DecisionTreeClassifier()\n",
    "logistic     = LogisticRegression(solver = \"lbfgs\", max_iter = 500)\n",
    "randomForest = RandomForestClassifier(n_estimators = 100)\n",
    "boostedTree  = GradientBoostingClassifier()\n",
    "svm          = SVC(gamma = \"scale\", probability = True)\n",
    "neuralNet    = MLPClassifier()\n",
    "neighbors    = KNeighborsClassifier()\n",
    "models = {\"tree\"         :tree,\n",
    "          \"logistic\"     :logistic,\n",
    "          \"randomForest\" :randomForest,\n",
    "          \"boostedTree\"  :boostedTree,\n",
    "          \"svm\"          :svm,\n",
    "          \"neuralNet\"    :neuralNet,\n",
    "          \"neighbors\"    :neighbors\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBCcFLDR67j3"
   },
   "outputs": [],
   "source": [
    "def stepwiseRegresion (model ,trainingSet, testSet, selectedFeatures: [str], target: [str]) -> DataFrame:\n",
    "\n",
    "    def computeAUC (forFeatures: [str]) -> ([str],float,float):\n",
    "        model.fit(trainingSet[forFeatures], trainingSet[target])\n",
    "\n",
    "        trainingSet[\"proba donor stepwise\"] = DataFrame(model.predict_proba(trainingSet[forFeatures]))[1]\n",
    "        testSet[\"proba donor stepwise\"]     = DataFrame(model.predict_proba(testSet[forFeatures]))[1]\n",
    "        \n",
    "        aucTraining = roc_auc_score(array(trainingSet[target]),array(trainingSet[\"proba donor stepwise\"]))\n",
    "        aucTest     = roc_auc_score(array(testSet[target]),array(testSet[\"proba donor stepwise\"]))\n",
    "\n",
    "        trainingSet.drop(\"proba donor stepwise\", axis = 1)\n",
    "        testSet.drop(\"proba donor stepwise\", axis = 1)\n",
    "\n",
    "        return (forFeatures,aucTraining,aucTest)\n",
    "\n",
    "    featuresOrder = []\n",
    "    forwardSelection = []\n",
    "\n",
    "    for step in range(len(selectedFeatures)):\n",
    "        print(f\"step {step+1}\")\n",
    "        aucs = []\n",
    "        for feature in selectedFeatures:\n",
    "            if feature not in featuresOrder:\n",
    "                modelFeatures = featuresOrder.copy()\n",
    "                modelFeatures.append(feature)\n",
    "                aucs.append(computeAUC(forFeatures = modelFeatures))\n",
    "\n",
    "        steps = DataFrame(aucs)\n",
    "        steps.columns = [\"Feature\",\"AUC training\", \"AUC test\"]\n",
    "        steps = steps.sort_values(by=[\"AUC test\"], ascending = False)\n",
    "\n",
    "        featuresOrder = steps[\"Feature\"].iloc[0]\n",
    "        forwardSelection.append((step+1, steps[\"Feature\"].iloc[0],steps[\"AUC training\"].iloc[0],steps[\"AUC test\"].iloc[0]))\n",
    "\n",
    "    df = DataFrame(forwardSelection)\n",
    "    df.columns = (\"Step\",\"Features\",\"AUC Train\",\"AUC Test\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1. GradientBoosingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UVNHPvBD67j7",
    "outputId": "b5d606f0-6aba-4bfb-e730-3b06f959bf9e"
   },
   "outputs": [],
   "source": [
    "forwardSelection = stepwiseRegresion(model = GradientBoostingClassifier(),\n",
    "                                     trainingSet      = trainingSet, \n",
    "                                     testSet          = validationSet, \n",
    "                                     selectedFeatures = ['18y', '10y', '5y', '3y', '1y', 'frequency_gifts', 'Q1', 'Q2', 'Q3','Q4', 'recency_number', 'is_french', 'gender_M', 'gender_NA', 'gender_S', 'province_Brussels', 'province_East Flanders', 'province_Flemish Brabant', 'province_Hainaut', 'province_Liege','province_Limburg', 'province_Luxembourg', 'province_Namur','province_Walloon Brabant', 'province_West Flanders'],\n",
    "                                     target           = 'amount_missing')\n",
    "forwardSelection.sort_values(\"AUC Train\",ascending=False).head(10)\n",
    "selectedfeaturesRFC=forwardSelection.sort_values(\"AUC Test\",ascending=False).get_value(0,1,takeable=True)\n",
    "print(selectedfeaturesRFC)\n",
    "print(forwardSelection.sort_values(\"AUC Test\",ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardSelection = stepwiseRegresion(model = SVC(gamma = \"scale\", probability = True),\n",
    "                                     trainingSet      = trainingSet, \n",
    "                                     testSet          = validationSet, \n",
    "                                     selectedFeatures = ['18y', '10y', '5y', '3y', '1y', 'frequency_gifts', 'Q1', 'Q2', 'Q3','Q4', 'recency_number', 'is_french', 'gender_M', 'gender_NA', 'gender_S', 'province_Brussels', 'province_East Flanders', 'province_Flemish Brabant', 'province_Hainaut', 'province_Liege','province_Limburg', 'province_Luxembourg', 'province_Namur','province_Walloon Brabant', 'province_West Flanders'],\n",
    "                                     target           = 'amount_missing')\n",
    "forwardSelection.sort_values(\"AUC Train\",ascending=False).head(10)\n",
    "selectedfeaturesRFC=forwardSelection.sort_values(\"AUC Test\",ascending=False).get_value(0,1,takeable=True)\n",
    "print(selectedfeaturesRFC)\n",
    "print(forwardSelection.sort_values(\"AUC Test\",ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardSelection = stepwiseRegresion(model = SVC(gamma = \"scale\", probability = True),\n",
    "                                     trainingSet      = trainingSet, \n",
    "                                     testSet          = validationSet, \n",
    "                                     selectedFeatures = ['18y', '10y', '5y', '3y', '1y', 'frequency_gifts', 'Q1', 'Q2', 'Q3','Q4', 'recency_number', 'is_french', 'gender_M', 'gender_NA', 'gender_S', 'province_Brussels', 'province_East Flanders', 'province_Flemish Brabant', 'province_Hainaut', 'province_Liege','province_Limburg', 'province_Luxembourg', 'province_Namur','province_Walloon Brabant', 'province_West Flanders'],\n",
    "                                     target           = 'amount_missing')\n",
    "forwardSelection.sort_values(\"AUC Train\",ascending=False).head(10)\n",
    "selectedfeaturesRFC=forwardSelection.sort_values(\"AUC Test\",ascending=False).get_value(0,1,takeable=True)\n",
    "print(selectedfeaturesRFC)\n",
    "print(forwardSelection.sort_values(\"AUC Test\",ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardSelection = stepwiseRegresion(model = KNeighborsClassifier(),\n",
    "                                     trainingSet      = trainingSet, \n",
    "                                     testSet          = validationSet, \n",
    "                                     selectedFeatures = ['18y', '10y', '5y', '3y', '1y', 'frequency_gifts', 'Q1', 'Q2', 'Q3','Q4', 'recency_number', 'is_french', 'gender_M', 'gender_NA', 'gender_S', 'province_Brussels', 'province_East Flanders', 'province_Flemish Brabant', 'province_Hainaut', 'province_Liege','province_Limburg', 'province_Luxembourg', 'province_Namur','province_Walloon Brabant', 'province_West Flanders'],\n",
    "                                     target           = 'amount_missing')\n",
    "forwardSelection.sort_values(\"AUC Train\",ascending=False).head(10)\n",
    "selectedfeaturesRFC=forwardSelection.sort_values(\"AUC Test\",ascending=False).get_value(0,1,takeable=True)\n",
    "print(selectedfeaturesRFC)\n",
    "print(forwardSelection.sort_values(\"AUC Test\",ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.5. Decission Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardSelection = stepwiseRegresion(model = DecisionTreeClassifier(),\n",
    "                                     trainingSet      = trainingSet, \n",
    "                                     testSet          = validationSet, \n",
    "                                     selectedFeatures = ['18y', '10y', '5y', '3y', '1y', 'frequency_gifts', 'Q1', 'Q2', 'Q3','Q4', 'recency_number', 'is_french', 'gender_M', 'gender_NA', 'gender_S', 'province_Brussels', 'province_East Flanders', 'province_Flemish Brabant', 'province_Hainaut', 'province_Liege','province_Limburg', 'province_Luxembourg', 'province_Namur','province_Walloon Brabant', 'province_West Flanders'],\n",
    "                                     target           = 'amount_missing')\n",
    "forwardSelection.sort_values(\"AUC Train\",ascending=False).head(10)\n",
    "selectedfeaturesRFC=forwardSelection.sort_values(\"AUC Test\",ascending=False).get_value(0,1,takeable=True)\n",
    "print(selectedfeaturesRFC)\n",
    "print(forwardSelection.sort_values(\"AUC Test\",ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardSelection = stepwiseRegresion(model = RandomForestClassifier(n_estimators = 100),\n",
    "                                     trainingSet      = trainingSet, \n",
    "                                     testSet          = validationSet, \n",
    "                                     selectedFeatures = ['18y', '10y', '5y', '3y', '1y', 'frequency_gifts', 'Q1', 'Q2', 'Q3','Q4', 'recency_number', 'is_french', 'gender_M', 'gender_NA', 'gender_S', 'province_Brussels', 'province_East Flanders', 'province_Flemish Brabant', 'province_Hainaut', 'province_Liege','province_Limburg', 'province_Luxembourg', 'province_Namur','province_Walloon Brabant', 'province_West Flanders'],\n",
    "                                     target           = 'amount_missing')\n",
    "forwardSelection.sort_values(\"AUC Train\",ascending=False).head(10)\n",
    "selectedfeaturesRFC=forwardSelection.sort_values(\"AUC Test\",ascending=False).get_value(0,1,takeable=True)\n",
    "print(selectedfeaturesRFC)\n",
    "print(forwardSelection.sort_values(\"AUC Test\",ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.7. MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardSelection = stepwiseRegresion(model = MLPClassifier(),\n",
    "                                     trainingSet      = trainingSet, \n",
    "                                     testSet          = validationSet, \n",
    "                                     selectedFeatures = ['18y', '10y', '5y', '3y', '1y', 'frequency_gifts', 'Q1', 'Q2', 'Q3','Q4', 'recency_number', 'is_french', 'gender_M', 'gender_NA', 'gender_S', 'province_Brussels', 'province_East Flanders', 'province_Flemish Brabant', 'province_Hainaut', 'province_Liege','province_Limburg', 'province_Luxembourg', 'province_Namur','province_Walloon Brabant', 'province_West Flanders'],\n",
    "                                     target           = 'amount_missing')\n",
    "forwardSelection.sort_values(\"AUC Train\",ascending=False).head(10)\n",
    "selectedfeaturesRFC=forwardSelection.sort_values(\"AUC Test\",ascending=False).get_value(0,1,takeable=True)\n",
    "print(selectedfeaturesRFC)\n",
    "print(forwardSelection.sort_values(\"AUC Test\",ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pL_sKASy67kK"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "              \n",
    "              \n",
    "## <center>5. Test Set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5yyEKKxA67kK"
   },
   "source": [
    "#### 5.1 Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OZ3he2JY67kL",
    "outputId": "6113079f-8065-4f85-aa21-9cb90964ddf1"
   },
   "outputs": [],
   "source": [
    "# - TEST SET - #\n",
    "\n",
    "gifts_14 = read_csv(inputData + \"/gifts.csv\", sep = ';')\n",
    "\n",
    "#Inspect the data\n",
    "explore(gifts_14)\n",
    "\n",
    "#Analyse the column camp id\n",
    "gifts_14['campID'] = gifts_14['campID'].apply(str)\n",
    "\n",
    "#Replace 0 in camp ID to NA\n",
    "gifts_14['campID'] = gifts_14['campID'].replace('0', 'NA')\n",
    "\n",
    "#Check the replacement of NAs\n",
    "(gifts_14.campID == 'NA').sum()\n",
    "\n",
    "#Extracting Year from the Date column\n",
    "gifts_14['date'] = pd.to_datetime(gifts_14['date'])\n",
    "gifts_14['year'] = gifts_14['date'].dt.year\n",
    "gifts_14['months'] = gifts_14['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QyAm21mu67kN"
   },
   "outputs": [],
   "source": [
    "# - TEST SET - #\n",
    "\n",
    "#Most recent date before 2013\n",
    "gifts_before_2014 = gifts_14[(gifts_14.date < '2013-12-17')]\n",
    "gifts_date_14 = gifts_before_2014.groupby('donorID')['date'].max()\n",
    "\n",
    "# Slice of 1 year\n",
    "gifts_new_1y_14 = gifts_14[(gifts_14.date < '2013-12-17') & (gifts_14.date > '2012-12-17')] \n",
    "\n",
    "#Grouping by Donor ofr 1 year \n",
    "gifts_1_year_14 = gifts_new_1y_14.groupby('donorID')['amount'].sum()\n",
    "\n",
    "#Slice for 3 years \n",
    "gifts_new_3y_14 = gifts_14[(gifts_14.date < '2013-12-17') & (gifts_14.date > '2010-12-17')]\n",
    "gifts_3_year_14 = gifts_new_3y_14.groupby('donorID')['amount'].sum()\n",
    "\n",
    "#Slice for 5 years \n",
    "gifts_new_5y_14 = gifts_14[(gifts_14.date < '2013-12-17') & (gifts_14.date > '2008-12-17')]\n",
    "gifts_5_year_14 = gifts_new_5y_14.groupby('donorID')['amount'].sum()\n",
    "\n",
    "#Slice for 10 years \n",
    "gifts_new_10y_14 = gifts_14[(gifts_14.date < '2013-12-17') & (gifts_14.date > '2003-12-17')]\n",
    "gifts_10_year_14 = gifts_new_10y_14.groupby('donorID')['amount'].sum()\n",
    "\n",
    "#Slice for 18 years \n",
    "gifts_new_18y_14 = gifts[(gifts.date < '2013-12-17') & (gifts_14.date > '1995-1-17')]\n",
    "gifts_18_year_14 = gifts_new_18y.groupby('donorID')['amount'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGunfHsw67kO",
    "outputId": "6f67a235-623b-4ec5-e6bf-242950e70ae8"
   },
   "outputs": [],
   "source": [
    "# - TEST SET - #\n",
    "\n",
    "#Create table for with total amount donated by donor in specific time period \n",
    "\n",
    "#Join data of 18y with 14y\n",
    "left_table = gifts_18_year_14\n",
    "right_table = gifts_10_year_14\n",
    "join_18_10_14 = pd.merge(left_table,\n",
    "        right_table,\n",
    "        how='left',\n",
    "        left_on='donorID',\n",
    "        right_on='donorID'\n",
    "        )\n",
    "#Join previous with 5y\n",
    "left_table = join_18_10_14\n",
    "right_table = gifts_5_year_14\n",
    "join_18_10_5_14 = pd.merge(left_table,\n",
    "        right_table,\n",
    "        how='left',\n",
    "        left_on='donorID',\n",
    "        right_on='donorID'\n",
    "        )\n",
    "#Join previous with 3y\n",
    "left_table = join_18_10_5_14\n",
    "right_table = gifts_3_year_14\n",
    "join_18_10_5_3_14 = pd.merge(left_table,\n",
    "        right_table,\n",
    "        how='left',\n",
    "        left_on='donorID',\n",
    "        right_on='donorID'\n",
    "        )\n",
    "#Join previous with 1y\n",
    "left_table = join_18_10_5_3_14\n",
    "right_table = gifts_1_year_14\n",
    "join_18_10_5_3_1_14 = pd.merge(left_table,\n",
    "        right_table,\n",
    "        how='left',\n",
    "        left_on='donorID',\n",
    "        right_on='donorID'\n",
    "        )\n",
    "#Changing names of columns\n",
    "join_18_10_5_3_1_14.columns = ['18y','10y','5y', '3y', '1y']\n",
    "final_merge_gifts_14 = join_18_10_5_3_1_14\n",
    "\n",
    "# Checking final result\n",
    "final_merge_gifts_14.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Bn5hPit67kQ",
    "outputId": "53d5df53-04e9-4045-8fd1-f94cc1170a9b"
   },
   "outputs": [],
   "source": [
    "# - TEST SET - #\n",
    "\n",
    "\n",
    "#Transform the dataset for better interpretation\n",
    "\n",
    "#Create pivot with every year\n",
    "gifts_1_14 = gifts_14.pivot_table(index = 'donorID', columns = ['year'], values = 'amount', aggfunc = 'sum')\n",
    "\n",
    "#Create pivot with every month\n",
    "gifts_2_14 = gifts_14.pivot_table(index = 'donorID', columns = ['months'], values = 'amount', aggfunc = 'sum')\n",
    "\n",
    "# merge the two pivots in one table\n",
    "gifts_final_14 = pd.merge(gifts_1, gifts_2, 'left', on= \"donorID\")\n",
    "\n",
    "#Fill NA with 0\n",
    "gifts_final_14 = gifts_final_14.iloc[:, 0:].fillna(0)\n",
    "\n",
    "#Create Column 'frequency_gifts'\n",
    "gifts_final_14[\"frequency_gifts\"] = ((gifts_final_14.iloc[:, 0:20]) > 0.0).sum(axis = 1)\n",
    "\n",
    "#Create quarters\n",
    "gifts_final_14['Q1'] = gifts_final_14.iloc[:, -13:-10].sum(axis = 1)\n",
    "gifts_final_14['Q2'] = gifts_final_14.iloc[:, -10:-7].sum(axis = 1)\n",
    "gifts_final_14['Q3'] = gifts_final_14.iloc[:, 26:29].sum(axis = 1)\n",
    "gifts_final_14['Q4'] = gifts_final_14.iloc[:, 29:32].sum(axis = 1)\n",
    "\n",
    "#Check data\n",
    "gifts_final_14.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vVmWdlUT67kY",
    "outputId": "cb1d0fd5-4276-4d16-e3c1-c61d4cad0fbf"
   },
   "outputs": [],
   "source": [
    "# - TEST SET - #\n",
    "\n",
    "#Drop months and yearss\n",
    "gifts_quarter_14 = gifts_final_14.drop(gifts_final_14.iloc[:,0:20], axis=1)\n",
    "\n",
    "#Create table with quarters and gifts\n",
    "left_table_a = final_merge_gifts_14\n",
    "right_table_a = gifts_quarter_14\n",
    "\n",
    "gifts_final_1_14 = pd.merge(left_table_a,\n",
    "                            right_table_a,\n",
    "                            how='left',\n",
    "                            left_on='donorID',\n",
    "                            right_on='donorID'\n",
    "                            )\n",
    "\n",
    "#Most recent date added to the gifts data base\n",
    "left_table_14 = gifts_final_1_14\n",
    "right_table_14 = gifts_date_14\n",
    "\n",
    "gifts_final_2_14 = pd.merge(left_table_14,\n",
    "                            right_table_14,\n",
    "                            how='left',\n",
    "                            left_on='donorID',\n",
    "                            right_on='donorID'\n",
    "                            )\n",
    "\n",
    "\n",
    "# create data frame with only this data\n",
    "date_1 = pd.to_datetime('2013-12-17')\n",
    "\n",
    "# add column 'recency_number' to new dataframe\n",
    "gifts_final_2_14['recency_number'] = date_1 - gifts_final_2_14['date'] \n",
    "\n",
    "# Covert to days instead of date\n",
    "gifts_final_2_14['recency_number'] = gifts_final_2_14['recency_number'] / np.timedelta64(1, 'D')\n",
    "gifts_final_2_14.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kS16iwXp67ka",
    "outputId": "d74e8a16-b782-4cc7-d7a5-5f6c3a19b2c9"
   },
   "outputs": [],
   "source": [
    "# - TEST SET - #\n",
    "\n",
    "#Read the campaign 2014 table\n",
    "c_2014 = read_csv(inputData + \"/campaign20140115.csv\", sep = ';')\n",
    "explore(c_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8z8WkgP67kc"
   },
   "outputs": [],
   "source": [
    "# - TEST SET - #\n",
    "\n",
    "#Merge the gifts_1 and c_2013 dataset\n",
    "left_1_14 = pd.merge(c_2014, \n",
    "                     gifts_final_2_14, \n",
    "                     how = \"left\",\n",
    "                     left_on = 'donorID', \n",
    "                     right_on = 'donorID')\n",
    "\n",
    "left_2_14 = pd.merge(left_1_14, \n",
    "                    donor, \n",
    "                    how = \"left\",\n",
    "                    left_on = 'donorID', \n",
    "                    right_on = 'donorID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9v7WRq7S67ke",
    "outputId": "014a21db-654c-46f3-d990-a590c16f184d"
   },
   "outputs": [],
   "source": [
    "# - DATA PREP - #\n",
    "\n",
    "#Create Dummies for gender, region and province\n",
    "final = pd.get_dummies(left_2, columns = ['gender'], drop_first=True)\n",
    "\n",
    "\n",
    "final['amount_missing'] = where(final['amount'].isnull(), 1, 0)\n",
    "\n",
    "# Appling condition for donations higher than 35 \n",
    "final['amount_missing'] = where(final['amount']>35, 1, 0)\n",
    "\n",
    "#Fix zipcode\n",
    "final['zipcode'] = final['zipcode'].str.replace(\"SW6 3PS\", '0')\n",
    "final['zipcode'] = final['zipcode'].str.replace(\" \", '0')\n",
    "final['zipcode'] = final['zipcode'].fillna(0)\n",
    "final['zipcode'] = final['zipcode'].astype(int)\n",
    "\n",
    "#Apply function to zipcode to add privince and regions names\n",
    "final[\"province\"] = final[\"zipcode\"].apply(lambda row:province(row))\n",
    "final[\"region\"] = final[\"zipcode\"].apply(lambda row:region(row))\n",
    "final.fillna(0)\n",
    "\n",
    "final = pd.get_dummies(final, columns = ['region'], drop_first=True)\n",
    "final = pd.get_dummies(final, columns = ['province'], drop_first=True)\n",
    "\n",
    "explore(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5yrhtwv67kg",
    "outputId": "8a71625d-3a7c-40e0-b67a-09a18e646d03"
   },
   "outputs": [],
   "source": [
    "\n",
    "final_model_14 = final.drop(final[['donorID','amount','date','zipcode']], axis = 1)\n",
    "final_model_14.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNenYuBP67kn",
    "outputId": "4056f883-2486-4e96-f899-d44acaed7627"
   },
   "outputs": [],
   "source": [
    "# - TEST SET - #\n",
    "\n",
    "#We have to drop one Gender beause it is redundant. It can cause ''Multicollinearity'' issues \n",
    "#Zipcode not necesary cause we have the dummies \n",
    "# change is out cause we have recency now\n",
    "# amount is our target\n",
    "# donorID is not needed either\n",
    "\n",
    "final_model_14 = final.drop(final[['donorID','amount','date','zipcode']], axis = 1)\n",
    "final_model_14.head()\n",
    "\n",
    "#Eliminate the months \n",
    "table_model_14 = final_model_14.drop(final_model_14.iloc[:, 5:17],axis = 1) \n",
    "table_model_14.tail()\n",
    "\n",
    "#Change the NA for 0 \n",
    "for column in table_model_14.columns:\n",
    "    if column in [\"18y\",\"10y\",\"5y\",\"3y\",\"1y\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"Q1\",\"Q2\",\"Q3\",\"Q4\",\"recency_number\",'frequency_gifts']:\n",
    "        table_model_14[column][np.isnan(table_model_14[column])] = 0\n",
    "table_model_14.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "siwnXK-O67kr"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## <center>6. Modeling the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5crbWwj67kt",
    "outputId": "db37d583-db80-4c5f-aefd-21f2327e9fcd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Using the Best Model, Gradient Boosting for classification\n",
    "\n",
    "selectedFeatures = ['Q3', 'frequency_gifts', '18y', 'province_Namur', 'province_Liege', 'province_Limburg', \n",
    "                    'gender_M', 'gender_NA', 'province_East Flanders', 'province_Brussels', 'province_Flemish Brabant',\n",
    "                    'province_Luxembourg', '3y', 'province_Walloon Brabant', 'province_West Flanders']\n",
    "target = \"amount_missing\"\n",
    "testSet=table_model_14\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(trainingSet[selectedFeatures], trainingSet[target])\n",
    "trainingSet[\"proba donor\"] = DataFrame(model.predict_proba(trainingSet[selectedFeatures]))[1]\n",
    "testSet[\"proba donor\"]     = DataFrame(model.predict_proba(testSet[selectedFeatures]))[1]\n",
    "rocTraining = roc(dataSet = trainingSet, actuals = target, probability = \"proba donor\")\n",
    "rocTest     = roc(dataSet = testSet,     actuals = target, probability = \"proba donor\")\n",
    "\n",
    "predictions   = model.predict(testSet[selectedFeatures])\n",
    "probabilities = DataFrame(model.predict_proba(testSet[selectedFeatures]))[1]\n",
    "accuracy      = accuracy_score(testSet[target],predictions)\n",
    "auc2           = roc_auc_score(array(testSet[target]),array(probabilities))\n",
    "\n",
    "print(accuracy)\n",
    "print(auc2)\n",
    "print(rocTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KFtsHUKA67kx",
    "outputId": "6fdfa6f2-eb07-4c7f-d566-97be59f0e399"
   },
   "outputs": [],
   "source": [
    "#ROC training set\n",
    "\n",
    "pyplot.plot(rocTraining[\"False positive rate\"], rocTraining[\"True positive rate\"])\n",
    "pyplot.plot([0, 1], [0, 1], 'k--')\n",
    "pyplot.xlim([0.0, 1.0])\n",
    "pyplot.ylim([0.0, 1.0])\n",
    "pyplot.xlabel(\"False Positive Rate or (1 - Specifity)\")\n",
    "pyplot.ylabel(\"True Positive Rate or (Sensitivity)\")\n",
    "pyplot.title(\"Receiver Operating Characteristic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4t-f4Lf67k0",
    "outputId": "d5f0b1cf-f7a3-413b-e6ce-90c74b03f0e3"
   },
   "outputs": [],
   "source": [
    "#ROC test set\n",
    "\n",
    "pyplot.plot(rocTest[\"False positive rate\"], rocTest[\"True positive rate\"])\n",
    "pyplot.plot([0, 1], [0, 1], 'k--')\n",
    "pyplot.xlim([0.0, 1.0])\n",
    "pyplot.ylim([0.0, 1.0])\n",
    "pyplot.xlabel(\"False Positive Rate or (1 - Specifity)\")\n",
    "pyplot.ylabel(\"True Positive Rate or (Sensitivity)\")\n",
    "pyplot.title(\"Receiver Operating Characteristic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KADGKwd567k1",
    "outputId": "752a934e-2685-4773-f22c-360bf3cc9771"
   },
   "outputs": [],
   "source": [
    "#Calculcate AUC for the best model\n",
    "\n",
    "aucTraining = auc(rocTraining[\"False positive rate\"],rocTraining[\"True positive rate\"])\n",
    "aucTest     = auc(rocTest[\"False positive rate\"],    rocTest[\"True positive rate\"])\n",
    "\n",
    "print(f\"auc training set : {aucTraining}\")\n",
    "print(f\"auc test set     : {aucTest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## <center> 7. Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xB4eC6O67k4"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "pts2 = pts.groupby(['proba donor']).sum()\n",
    "pts2.reset_index(inplace=True)\n",
    "sns.barplot(y='amount_missing', x='proba donor', data=pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8inJMzL067k5"
   },
   "outputs": [],
   "source": [
    "# To stratify\n",
    "from sklearn.model_selection import train_test_split \n",
    " X_train, X_test, y_train, y_test =    train_test_split(X, y, test_size=0.3,                     random_state=21, stratify=y)\n",
    "\n",
    "#Oversampling\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=5000, n_features=2, n_informative=2,\n",
    "                            n_redundant=0, n_repeated=0, n_classes=3,\n",
    "                            n_clusters_per_class=1,\n",
    "                            weights=[0.01, 0.05, 0.94],\n",
    "                            class_sep=0.8, random_state=0)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_resampled, y_resampled) # doctest : +ELLIPSIS\n",
    "\n",
    "import numpy as np\n",
    "X_hetero = np.array([['xxx', 1, 1.0], ['yyy', 2, 2.0], ['zzz', 3, 3.0]],\n",
    "                    dtype=np.object)\n",
    "y_hetero = np.array([0, 0, 1])\n",
    "X_resampled, y_resampled = ros.fit_resample(X_hetero, y_hetero)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Code_DSC_BetsySarahAndresCarlosBrayan_Final3.1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
